{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bVYE7y4Y009g"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ElO1xwlT1Z1Y"
   },
   "outputs": [],
   "source": [
    "input_size = 3072\n",
    "hidden_size = 400\n",
    "neck_size = 128\n",
    "num_classes = 784\n",
    "num_epochs = 10\n",
    "batch_size = 100\n",
    "iterations = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102,
     "referenced_widgets": [
      "33d915e9da624cafb9ca0afd1d57334d",
      "db953150811c4c95b13f8b3126f228eb",
      "cdd89a66d3414fd7ac1a2dae21610f44",
      "7f8e79e9e06a4076ad04d89128ee2bba",
      "f3bc3e4a882a4e6a9d4691e650f2c693",
      "063e5a53b117491a9fc024c317e06c74",
      "5447aa1499f34ef496309eb0136ad13c",
      "ec5564e39470444a84d48f95036d501c"
     ]
    },
    "colab_type": "code",
    "id": "lhNeEmGB1eIw",
    "outputId": "95b51996-31e0-4b32-a247-65ab6a989009"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d915e9da624cafb9ca0afd1d57334d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    }
   ],
   "source": [
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_dataset = dsets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=trans,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_dataset = dsets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=trans\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NTc-ESe61ii9"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0FTem6Hn1ncB"
   },
   "outputs": [],
   "source": [
    "class PerceptrAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE, self).__init__()\n",
    "        # Encoder\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, neck_size)\n",
    "        # Decoder\n",
    "        self.fc4 = nn.Linear(neck_size, hidden_size)\n",
    "        self.fc6 = nn.Linear(hidden_size, input_size)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def decode(self, x):\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = torch.sigmoid(self.fc6(x))\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.encode(x)\n",
    "        out = self.decode(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MaCSgGvdHBr4"
   },
   "outputs": [],
   "source": [
    "class ConvAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAE, self).__init__()\n",
    "        # Encoder\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2), \n",
    "                                    nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(16, 8, kernel_size=5, stride=1, padding=2), \n",
    "                                    nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(8, 8, kernel_size=5, stride=1, padding=2), \n",
    "                                    nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        # Decoder\n",
    "        self.layer4 = nn.Sequential(nn.Conv2d(8, 8, kernel_size=5, stride=1, padding=2), \n",
    "                                    nn.ReLU(), nn.Upsample(scale_factor=2, mode='bilinear'))\n",
    "        self.layer5 = nn.Sequential(nn.Conv2d(8, 16, kernel_size=5, stride=1, padding=2), \n",
    "                                    nn.ReLU(), nn.Upsample(scale_factor=2, mode='bilinear'))\n",
    "        self.layer6 = nn.Sequential(nn.Conv2d(16, 3, kernel_size=5, stride=1, padding=2), \n",
    "                                    nn.Sigmoid(), nn.Upsample(scale_factor=2, mode='bilinear'))\n",
    "    \n",
    "    def encode(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out) \n",
    "        return out\n",
    "    \n",
    "    def decode(self, x):\n",
    "        out = self.layer4(x)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out) \n",
    "        return out\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.encode(x)\n",
    "        out = self.decode(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 996
    },
    "colab_type": "code",
    "id": "8H4-Hx0hLG_C",
    "outputId": "68d069cf-e974-4cf0-d2af-0014c8b026bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2506: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [0/500], Loss: 1.1890079975128174\n",
      "Epoch [1/10], Step [100/500], Loss: 0.606131911277771\n",
      "Epoch [1/10], Step [200/500], Loss: 0.641532301902771\n",
      "Epoch [1/10], Step [300/500], Loss: 0.6819426417350769\n",
      "Epoch [1/10], Step [400/500], Loss: 0.5779098868370056\n",
      "Epoch [2/10], Step [0/500], Loss: 0.7202984690666199\n",
      "Epoch [2/10], Step [100/500], Loss: 0.6899333000183105\n",
      "Epoch [2/10], Step [200/500], Loss: 0.6573451161384583\n",
      "Epoch [2/10], Step [300/500], Loss: 0.6309413909912109\n",
      "Epoch [2/10], Step [400/500], Loss: 0.6087682843208313\n",
      "Epoch [3/10], Step [0/500], Loss: 0.5527730584144592\n",
      "Epoch [3/10], Step [100/500], Loss: 0.6258824467658997\n",
      "Epoch [3/10], Step [200/500], Loss: 0.5422277450561523\n",
      "Epoch [3/10], Step [300/500], Loss: 0.594713032245636\n",
      "Epoch [3/10], Step [400/500], Loss: 0.5183201432228088\n",
      "Epoch [4/10], Step [0/500], Loss: 0.5123148560523987\n",
      "Epoch [4/10], Step [100/500], Loss: 0.6159372329711914\n",
      "Epoch [4/10], Step [200/500], Loss: 0.5803899765014648\n",
      "Epoch [4/10], Step [300/500], Loss: 0.5041124820709229\n",
      "Epoch [4/10], Step [400/500], Loss: 0.5862443447113037\n",
      "Epoch [5/10], Step [0/500], Loss: 0.4878680109977722\n",
      "Epoch [5/10], Step [100/500], Loss: 0.5340587496757507\n",
      "Epoch [5/10], Step [200/500], Loss: 0.5801242589950562\n",
      "Epoch [5/10], Step [300/500], Loss: 0.5186485052108765\n",
      "Epoch [5/10], Step [400/500], Loss: 0.5061064958572388\n",
      "Epoch [6/10], Step [0/500], Loss: 0.6124027967453003\n",
      "Epoch [6/10], Step [100/500], Loss: 0.46689119935035706\n",
      "Epoch [6/10], Step [200/500], Loss: 0.47668707370758057\n",
      "Epoch [6/10], Step [300/500], Loss: 0.5299109220504761\n",
      "Epoch [6/10], Step [400/500], Loss: 0.5005131959915161\n",
      "Epoch [7/10], Step [0/500], Loss: 0.517808735370636\n",
      "Epoch [7/10], Step [100/500], Loss: 0.5471468567848206\n",
      "Epoch [7/10], Step [200/500], Loss: 0.5703654289245605\n",
      "Epoch [7/10], Step [300/500], Loss: 0.5075035095214844\n",
      "Epoch [7/10], Step [400/500], Loss: 0.5364359021186829\n",
      "Epoch [8/10], Step [0/500], Loss: 0.5167288184165955\n",
      "Epoch [8/10], Step [100/500], Loss: 0.44432541728019714\n",
      "Epoch [8/10], Step [200/500], Loss: 0.4734201729297638\n",
      "Epoch [8/10], Step [300/500], Loss: 0.4985211193561554\n",
      "Epoch [8/10], Step [400/500], Loss: 0.4941680431365967\n",
      "Epoch [9/10], Step [0/500], Loss: 0.6046854853630066\n",
      "Epoch [9/10], Step [100/500], Loss: 0.49157389998435974\n",
      "Epoch [9/10], Step [200/500], Loss: 0.5439820885658264\n",
      "Epoch [9/10], Step [300/500], Loss: 0.4358207881450653\n",
      "Epoch [9/10], Step [400/500], Loss: 0.4954260289669037\n",
      "Epoch [10/10], Step [0/500], Loss: 0.5367139577865601\n",
      "Epoch [10/10], Step [100/500], Loss: 0.5355404615402222\n",
      "Epoch [10/10], Step [200/500], Loss: 0.5596133470535278\n",
      "Epoch [10/10], Step [300/500], Loss: 0.5276357531547546\n",
      "Epoch [10/10], Step [400/500], Loss: 0.4599584937095642\n",
      "CPU times: user 1min 30s, sys: 2.61 s, total: 1min 32s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "autoencoder = ConvAE().cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=learning_rate)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "      for i, (image, labels) in enumerate(train_loader):\n",
    "            image = image.to(torch.device('cuda'))\n",
    "\n",
    "            out_image = autoencoder(image)\n",
    "            loss = criterion(out_image, image)\n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % batch_size == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {}'\n",
    "                    .format(epoch + 1, num_epochs, i, total_step, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 961
    },
    "colab_type": "code",
    "id": "b8_0EpET5tKB",
    "outputId": "bb9a497a-2fbc-4da1-b84a-009cad3752d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2506: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [0/500], Loss: 0.4696296155452728\n",
      "Epoch [1/10], Step [100/500], Loss: 0.6005987524986267\n",
      "Epoch [1/10], Step [200/500], Loss: 0.5246269702911377\n",
      "Epoch [1/10], Step [300/500], Loss: 0.5158776044845581\n",
      "Epoch [1/10], Step [400/500], Loss: 0.4770846664905548\n",
      "Epoch [2/10], Step [0/500], Loss: 0.5511453151702881\n",
      "Epoch [2/10], Step [100/500], Loss: 0.4556095600128174\n",
      "Epoch [2/10], Step [200/500], Loss: 0.4395073652267456\n",
      "Epoch [2/10], Step [300/500], Loss: 0.5440658926963806\n",
      "Epoch [2/10], Step [400/500], Loss: 0.5001341104507446\n",
      "Epoch [3/10], Step [0/500], Loss: 0.5373076796531677\n",
      "Epoch [3/10], Step [100/500], Loss: 0.5253438353538513\n",
      "Epoch [3/10], Step [200/500], Loss: 0.6252644062042236\n",
      "Epoch [3/10], Step [300/500], Loss: 0.4697343707084656\n",
      "Epoch [3/10], Step [400/500], Loss: 0.5373998284339905\n",
      "Epoch [4/10], Step [0/500], Loss: 0.4938448667526245\n",
      "Epoch [4/10], Step [100/500], Loss: 0.5330120325088501\n",
      "Epoch [4/10], Step [200/500], Loss: 0.532616913318634\n",
      "Epoch [4/10], Step [300/500], Loss: 0.5207388997077942\n",
      "Epoch [4/10], Step [400/500], Loss: 0.5510818362236023\n",
      "Epoch [5/10], Step [0/500], Loss: 0.4607531726360321\n",
      "Epoch [5/10], Step [100/500], Loss: 0.5771632790565491\n",
      "Epoch [5/10], Step [200/500], Loss: 0.5353452563285828\n",
      "Epoch [5/10], Step [300/500], Loss: 0.4786677062511444\n",
      "Epoch [5/10], Step [400/500], Loss: 0.5136404633522034\n",
      "Epoch [6/10], Step [0/500], Loss: 0.5648112893104553\n",
      "Epoch [6/10], Step [100/500], Loss: 0.6042975187301636\n",
      "Epoch [6/10], Step [200/500], Loss: 0.545930802822113\n",
      "Epoch [6/10], Step [300/500], Loss: 0.5048285126686096\n",
      "Epoch [6/10], Step [400/500], Loss: 0.4624093770980835\n",
      "Epoch [7/10], Step [0/500], Loss: 0.5164763331413269\n",
      "Epoch [7/10], Step [100/500], Loss: 0.47795426845550537\n",
      "Epoch [7/10], Step [200/500], Loss: 0.5389444828033447\n",
      "Epoch [7/10], Step [300/500], Loss: 0.49320948123931885\n",
      "Epoch [7/10], Step [400/500], Loss: 0.47410616278648376\n",
      "Epoch [8/10], Step [0/500], Loss: 0.4311523139476776\n",
      "Epoch [8/10], Step [100/500], Loss: 0.46398916840553284\n",
      "Epoch [8/10], Step [200/500], Loss: 0.5548528432846069\n",
      "Epoch [8/10], Step [300/500], Loss: 0.45961621403694153\n",
      "Epoch [8/10], Step [400/500], Loss: 0.4779406785964966\n",
      "Epoch [9/10], Step [0/500], Loss: 0.4891427755355835\n",
      "Epoch [9/10], Step [100/500], Loss: 0.4692676365375519\n",
      "Epoch [9/10], Step [200/500], Loss: 0.4533514380455017\n",
      "Epoch [9/10], Step [300/500], Loss: 0.49892374873161316\n",
      "Epoch [9/10], Step [400/500], Loss: 0.4873458445072174\n",
      "Epoch [10/10], Step [0/500], Loss: 0.4941609799861908\n",
      "Epoch [10/10], Step [100/500], Loss: 0.540799081325531\n",
      "Epoch [10/10], Step [200/500], Loss: 0.4843956530094147\n",
      "Epoch [10/10], Step [300/500], Loss: 0.4700356125831604\n",
      "Epoch [10/10], Step [400/500], Loss: 0.5497615933418274\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (image, labels) in enumerate(train_loader):\n",
    "        image = image.to(torch.device('cuda'))\n",
    "  \n",
    "        out_image = autoencoder(image)\n",
    "        loss = criterion(out_image, image)\n",
    "        loss_list.append(loss.item())\n",
    "      \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "        if i % batch_size == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {}'\n",
    "                  .format(epoch + 1, num_epochs, i, total_step, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Sc1M5wlf0ro"
   },
   "outputs": [],
   "source": [
    "# baseline\n",
    "class ConvClassyfier(nn.Module): \n",
    "    def __init__(self): \n",
    "        super(ConvClassyfier, self).__init__() \n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2), \n",
    "                                    nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2)) \n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2), \n",
    "                                    nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=2), \n",
    "                                    nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer4 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2), \n",
    "                                    nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer5 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=2, stride=2, padding=1), \n",
    "                                    nn.ReLU(), nn.MaxPool2d(kernel_size=2))  \n",
    "        self.drop_out = nn.Dropout() \n",
    "        self.fc1 = nn.Linear(256, 512) \n",
    "        self.fc2 = nn.Linear(512, 374)\n",
    "        self.fc3 = nn.Linear(374, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x.reshape(x.size(0), -1)  \n",
    "        out = self.layer1(x) \n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out) \n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = out.reshape(out.size(0), -1) \n",
    "        out = self.drop_out(out) \n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out)) \n",
    "        out = F.log_softmax(self.fc3(out)) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 958
    },
    "colab_type": "code",
    "id": "IQWr7Iu_Yp7r",
    "outputId": "943f03e9-8e00-497f-f965-813ba35cce20"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [0/500], Loss: 2.298551082611084\n",
      "Epoch [1/10], Step [100/500], Loss: 1.789108157157898\n",
      "Epoch [1/10], Step [200/500], Loss: 1.6721948385238647\n",
      "Epoch [1/10], Step [300/500], Loss: 1.4951080083847046\n",
      "Epoch [1/10], Step [400/500], Loss: 1.4783755540847778\n",
      "Epoch [2/10], Step [0/500], Loss: 1.4158830642700195\n",
      "Epoch [2/10], Step [100/500], Loss: 1.2945237159729004\n",
      "Epoch [2/10], Step [200/500], Loss: 1.2300673723220825\n",
      "Epoch [2/10], Step [300/500], Loss: 1.3615756034851074\n",
      "Epoch [2/10], Step [400/500], Loss: 1.132836103439331\n",
      "Epoch [3/10], Step [0/500], Loss: 1.1295536756515503\n",
      "Epoch [3/10], Step [100/500], Loss: 0.9369361996650696\n",
      "Epoch [3/10], Step [200/500], Loss: 1.1858471632003784\n",
      "Epoch [3/10], Step [300/500], Loss: 0.9874433875083923\n",
      "Epoch [3/10], Step [400/500], Loss: 0.9776670336723328\n",
      "Epoch [4/10], Step [0/500], Loss: 0.9711243510246277\n",
      "Epoch [4/10], Step [100/500], Loss: 0.4742954969406128\n",
      "Epoch [4/10], Step [200/500], Loss: 0.9344733357429504\n",
      "Epoch [4/10], Step [300/500], Loss: 0.7995976805686951\n",
      "Epoch [4/10], Step [400/500], Loss: 0.7426221370697021\n",
      "Epoch [5/10], Step [0/500], Loss: 0.7130883932113647\n",
      "Epoch [5/10], Step [100/500], Loss: 0.6841021180152893\n",
      "Epoch [5/10], Step [200/500], Loss: 0.712045431137085\n",
      "Epoch [5/10], Step [300/500], Loss: 0.6929665207862854\n",
      "Epoch [5/10], Step [400/500], Loss: 0.6586480140686035\n",
      "Epoch [6/10], Step [0/500], Loss: 0.5913812518119812\n",
      "Epoch [6/10], Step [100/500], Loss: 0.6261690258979797\n",
      "Epoch [6/10], Step [200/500], Loss: 0.5880205631256104\n",
      "Epoch [6/10], Step [300/500], Loss: 0.6267474293708801\n",
      "Epoch [6/10], Step [400/500], Loss: 0.660206139087677\n",
      "Epoch [7/10], Step [0/500], Loss: 0.6274271607398987\n",
      "Epoch [7/10], Step [100/500], Loss: 0.4530107080936432\n",
      "Epoch [7/10], Step [200/500], Loss: 0.5577070713043213\n",
      "Epoch [7/10], Step [300/500], Loss: 0.6593277454376221\n",
      "Epoch [7/10], Step [400/500], Loss: 0.5263900756835938\n",
      "Epoch [8/10], Step [0/500], Loss: 0.5000607967376709\n",
      "Epoch [8/10], Step [100/500], Loss: 0.559499204158783\n",
      "Epoch [8/10], Step [200/500], Loss: 0.574280321598053\n",
      "Epoch [8/10], Step [300/500], Loss: 0.6061457395553589\n",
      "Epoch [8/10], Step [400/500], Loss: 0.5489780902862549\n",
      "Epoch [9/10], Step [0/500], Loss: 0.3526284098625183\n",
      "Epoch [9/10], Step [100/500], Loss: 0.32486939430236816\n",
      "Epoch [9/10], Step [200/500], Loss: 0.4908403754234314\n",
      "Epoch [9/10], Step [300/500], Loss: 0.5410892963409424\n",
      "Epoch [9/10], Step [400/500], Loss: 0.6088199019432068\n",
      "Epoch [10/10], Step [0/500], Loss: 0.38380497694015503\n",
      "Epoch [10/10], Step [100/500], Loss: 0.3429860770702362\n",
      "Epoch [10/10], Step [200/500], Loss: 0.23047585785388947\n",
      "Epoch [10/10], Step [300/500], Loss: 0.4798145592212677\n",
      "Epoch [10/10], Step [400/500], Loss: 0.372524231672287\n",
      "CPU times: user 1min 33s, sys: 2.2 s, total: 1min 35s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = ConvClassyfier().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "   for i, (image, labels) in enumerate(train_loader):\n",
    "     image = image.to(torch.device('cuda'))\n",
    "     labels = labels.to(torch.device('cuda'))\n",
    "     # image, labels = image.view(-1, 32, 32), labels.view(-1, 10)\n",
    "\n",
    "     outputs = model(image)\n",
    "     loss = criterion(outputs, labels)\n",
    "     loss_list.append(loss.item())\n",
    "\n",
    "     optimizer.zero_grad()\n",
    "     loss.backward()\n",
    "     optimizer.step()\n",
    "\n",
    "     if i % batch_size == 0:\n",
    "         print('Epoch [{}/{}], Step [{}/{}], Loss: {}'\n",
    "             .format(epoch + 1, num_epochs, i, total_step, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 923
    },
    "colab_type": "code",
    "id": "2JdNMRzYoU7O",
    "outputId": "f7cc4210-59a9-4cf5-becf-586151c626c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [0/500], Loss: 0.3321221172809601\n",
      "Epoch [1/10], Step [100/500], Loss: 0.5408867001533508\n",
      "Epoch [1/10], Step [200/500], Loss: 0.3831905722618103\n",
      "Epoch [1/10], Step [300/500], Loss: 0.47524967789649963\n",
      "Epoch [1/10], Step [400/500], Loss: 0.3054683804512024\n",
      "Epoch [2/10], Step [0/500], Loss: 0.29435834288597107\n",
      "Epoch [2/10], Step [100/500], Loss: 0.17314183712005615\n",
      "Epoch [2/10], Step [200/500], Loss: 0.2673536539077759\n",
      "Epoch [2/10], Step [300/500], Loss: 0.2401295155286789\n",
      "Epoch [2/10], Step [400/500], Loss: 0.21355368196964264\n",
      "Epoch [3/10], Step [0/500], Loss: 0.28339818120002747\n",
      "Epoch [3/10], Step [100/500], Loss: 0.12111752480268478\n",
      "Epoch [3/10], Step [200/500], Loss: 0.2966020703315735\n",
      "Epoch [3/10], Step [300/500], Loss: 0.4660169184207916\n",
      "Epoch [3/10], Step [400/500], Loss: 0.31218981742858887\n",
      "Epoch [4/10], Step [0/500], Loss: 0.2487531304359436\n",
      "Epoch [4/10], Step [100/500], Loss: 0.22194026410579681\n",
      "Epoch [4/10], Step [200/500], Loss: 0.4839268624782562\n",
      "Epoch [4/10], Step [300/500], Loss: 0.4303973913192749\n",
      "Epoch [4/10], Step [400/500], Loss: 0.27525079250335693\n",
      "Epoch [5/10], Step [0/500], Loss: 0.2429940402507782\n",
      "Epoch [5/10], Step [100/500], Loss: 0.3004068434238434\n",
      "Epoch [5/10], Step [200/500], Loss: 0.29383352398872375\n",
      "Epoch [5/10], Step [300/500], Loss: 0.15777546167373657\n",
      "Epoch [5/10], Step [400/500], Loss: 0.25888198614120483\n",
      "Epoch [6/10], Step [0/500], Loss: 0.11032713204622269\n",
      "Epoch [6/10], Step [100/500], Loss: 0.11981465667486191\n",
      "Epoch [6/10], Step [200/500], Loss: 0.16890636086463928\n",
      "Epoch [6/10], Step [300/500], Loss: 0.2609401047229767\n",
      "Epoch [6/10], Step [400/500], Loss: 0.13674376904964447\n",
      "Epoch [7/10], Step [0/500], Loss: 0.20354942977428436\n",
      "Epoch [7/10], Step [100/500], Loss: 0.13147781789302826\n",
      "Epoch [7/10], Step [200/500], Loss: 0.14360973238945007\n",
      "Epoch [7/10], Step [300/500], Loss: 0.21672022342681885\n",
      "Epoch [7/10], Step [400/500], Loss: 0.18765059113502502\n",
      "Epoch [8/10], Step [0/500], Loss: 0.09817671030759811\n",
      "Epoch [8/10], Step [100/500], Loss: 0.26012369990348816\n",
      "Epoch [8/10], Step [200/500], Loss: 0.10286545008420944\n",
      "Epoch [8/10], Step [300/500], Loss: 0.15705545246601105\n",
      "Epoch [8/10], Step [400/500], Loss: 0.3367809057235718\n",
      "Epoch [9/10], Step [0/500], Loss: 0.15859870612621307\n",
      "Epoch [9/10], Step [100/500], Loss: 0.25050655007362366\n",
      "Epoch [9/10], Step [200/500], Loss: 0.10454204678535461\n",
      "Epoch [9/10], Step [300/500], Loss: 0.11864270269870758\n",
      "Epoch [9/10], Step [400/500], Loss: 0.1612219661474228\n",
      "Epoch [10/10], Step [0/500], Loss: 0.06488330662250519\n",
      "Epoch [10/10], Step [100/500], Loss: 0.18139496445655823\n",
      "Epoch [10/10], Step [200/500], Loss: 0.08743565529584885\n",
      "Epoch [10/10], Step [300/500], Loss: 0.20863910019397736\n",
      "Epoch [10/10], Step [400/500], Loss: 0.2678511142730713\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "     for i, (image, labels) in enumerate(train_loader):\n",
    "        image = image.to(torch.device('cuda'))\n",
    "        labels = labels.to(torch.device('cuda'))\n",
    "\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % batch_size == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {}'\n",
    "                .format(epoch + 1, num_epochs, i, total_step, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pwx3a4aj8qIC"
   },
   "outputs": [],
   "source": [
    "class DE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DE, self).__init__()\n",
    "        # Encoder \n",
    "        self.fc1 = nn.Linear(input_size * 2, neck_size)\n",
    "        # Decoder\n",
    "        self.fc2 = nn.Linear(neck_size + input_size, input_size)\n",
    "\n",
    "        def encode(self, x, y):\n",
    "            x = F.relu(self.fc1(x, y))\n",
    "            return x\n",
    "\n",
    "        def decode(self, x, y):\n",
    "            x = torch.sigmoid(self.fc2(x, y))\n",
    "            return x\n",
    "\n",
    "        def forward(self, x, y):\n",
    "            out = self.encode(x, y)\n",
    "            out = self.decode(out, y)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "I37X5mCMccBt",
    "outputId": "f3603a98-9fce-44fe-f748-6eba1715f346"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10K test images: 72 %\n",
      "CPU times: user 1.58 s, sys: 8.93 ms, total: 1.59 s\n",
      "Wall time: 1.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "for i, (image, labels) in enumerate(test_loader):\n",
    "  # image = image.view(-1, input_size)\n",
    "  image = image.to(torch.device('cuda'))\n",
    "  labels = labels.to(torch.device('cuda'))\n",
    "  # image, labels = Variable(image), Variable(labels)\n",
    "  # outputs = autoencoder(image)\n",
    "  # outputs, labels = Variable(outputs), Variable(labels)\n",
    "  outputs = model(image)\n",
    "  _, predicted = torch.max(outputs.data, 1)  # Выбор лучшего класса из выходных данных: класс с лучшим счетом\n",
    "  total += labels.size(0)                    # Увеличиваем суммарный счет\n",
    "  correct += (predicted == labels).sum()     # Увеличиваем корректный счет\n",
    "     \n",
    "print('Accuracy of the network on the 10K test images: %d %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "063e5a53b117491a9fc024c317e06c74": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33d915e9da624cafb9ca0afd1d57334d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cdd89a66d3414fd7ac1a2dae21610f44",
       "IPY_MODEL_7f8e79e9e06a4076ad04d89128ee2bba"
      ],
      "layout": "IPY_MODEL_db953150811c4c95b13f8b3126f228eb"
     }
    },
    "5447aa1499f34ef496309eb0136ad13c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f8e79e9e06a4076ad04d89128ee2bba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec5564e39470444a84d48f95036d501c",
      "placeholder": "​",
      "style": "IPY_MODEL_5447aa1499f34ef496309eb0136ad13c",
      "value": "170500096it [00:01, 87410615.53it/s]"
     }
    },
    "cdd89a66d3414fd7ac1a2dae21610f44": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_063e5a53b117491a9fc024c317e06c74",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f3bc3e4a882a4e6a9d4691e650f2c693",
      "value": 1
     }
    },
    "db953150811c4c95b13f8b3126f228eb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec5564e39470444a84d48f95036d501c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3bc3e4a882a4e6a9d4691e650f2c693": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
