{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]) \n",
    "\n",
    "train_dataset = dsets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=trans,\n",
    "    download=True\n",
    ")\n",
    " \n",
    "test_dataset = dsets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=trans\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    " \n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module): \n",
    "    def __init__(self): \n",
    "        super(ConvNet, self).__init__() \n",
    "        self.layer1 = nn.Sequential( nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2), \n",
    "                                    nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2)) \n",
    "        self.layer2 = nn.Sequential( nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2), \n",
    "                                    nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2)) \n",
    "        self.drop_out = nn.Dropout() \n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 1000) \n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "    \n",
    "    def forward(self, x): \n",
    "        out = self.layer1(x) \n",
    "        out = self.layer2(out) \n",
    "        out = out.reshape(out.size(0), -1) \n",
    "        out = self.drop_out(out) \n",
    "        out = self.fc1(out) \n",
    "        out = self.fc2(out) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.1144, Accuracy: 95.00%\n",
      "Epoch [1/5], Step [200/600], Loss: 0.1908, Accuracy: 94.00%\n",
      "Epoch [1/5], Step [300/600], Loss: 0.0208, Accuracy: 100.00%\n",
      "Epoch [1/5], Step [400/600], Loss: 0.0152, Accuracy: 100.00%\n",
      "Epoch [1/5], Step [500/600], Loss: 0.0852, Accuracy: 97.00%\n",
      "Epoch [1/5], Step [600/600], Loss: 0.0886, Accuracy: 98.00%\n",
      "Epoch [2/5], Step [100/600], Loss: 0.1330, Accuracy: 95.00%\n",
      "Epoch [2/5], Step [200/600], Loss: 0.0661, Accuracy: 98.00%\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0876, Accuracy: 96.00%\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0367, Accuracy: 98.00%\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0297, Accuracy: 100.00%\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0358, Accuracy: 99.00%\n",
      "Epoch [3/5], Step [100/600], Loss: 0.1358, Accuracy: 98.00%\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0983, Accuracy: 97.00%\n",
      "Epoch [3/5], Step [300/600], Loss: 0.1408, Accuracy: 97.00%\n",
      "Epoch [3/5], Step [400/600], Loss: 0.1018, Accuracy: 97.00%\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0901, Accuracy: 97.00%\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0827, Accuracy: 97.00%\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0159, Accuracy: 100.00%\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0504, Accuracy: 98.00%\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0421, Accuracy: 99.00%\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0234, Accuracy: 100.00%\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0443, Accuracy: 98.00%\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0265, Accuracy: 99.00%\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0302, Accuracy: 99.00%\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0247, Accuracy: 100.00%\n",
      "Epoch [5/5], Step [300/600], Loss: 0.1398, Accuracy: 96.00%\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0281, Accuracy: 98.00%\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0355, Accuracy: 99.00%\n",
      "Epoch [5/5], Step [600/600], Loss: 0.1422, Accuracy: 97.00%\n",
      "CPU times: user 50min 9s, sys: 54.4 s, total: 51min 3s\n",
      "Wall time: 10min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                          (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10K test images: 98 %\n",
      "CPU times: user 9.93 s, sys: 109 ms, total: 10 s\n",
      "Wall time: 3.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Inference time on unoptimized model\n",
    "\n",
    "for i, (images, labels) in enumerate(test_loader):\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)  # Выбор лучшего класса из выходных данных: класс с лучшим счетом\n",
    "    total += labels.size(0)                    # Увеличиваем суммарный счет\n",
    "    correct += (predicted == labels).sum()     # Увеличиваем корректный счет\n",
    "       \n",
    "print('Accuracy of the network on the 10K test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "import torch.onnx\n",
    "import torchvision\n",
    "\n",
    "dummy_input = torch.randn(batch_size, 1, 28, 28)\n",
    "torch.onnx.export(model, dummy_input, \"cnn.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extacting model after inference\n",
    "import openvino.inference_engine\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "\n",
    "plugin_dir = None\n",
    "model_xml = '/home/irek/Works/3kurs/Science/Autoencoder/cnn.xml'\n",
    "model_bin = '/home/irek/Works/3kurs/Science/Autoencoder/cnn.bin'\n",
    "plugin = IEPlugin(\"CPU\", plugin_dirs=plugin_dir)\n",
    "net_vino = IENetwork(model=model_xml, weights=model_bin)\n",
    "exec_net = plugin.load(network = net_vino)\n",
    "input_blob = next(iter(net_vino.inputs))\n",
    "output_blob = next(iter(net_vino.outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.48 s, sys: 60.1 ms, total: 8.54 s\n",
      "Wall time: 5.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Inference on optimized model\n",
    "\n",
    "for i, (images, labels) in enumerate(test_loader):\n",
    "    res = exec_net.infer(inputs = {input_blob: images})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
